# 📸 多源图片爬虫

这是一个基于 Python 的多进程并发图片爬虫项目，旨在高效地从主流搜索引擎批量下载特定关键词的图片。

## ✨ 功能特性

* **多源支持**：集成 **百度**、**必应 (Bing)**、**搜狗 (Sogou)**、**360 (So)** 四大图库接口。
* **高效并发**：采用 `multiprocessing` 多进程架构，将 URL 抓取与图片下载分离，充分利用多核 CPU。
* **异步加速**：爬虫核心逻辑使用 `aiohttp` 异步网络请求，大幅提升抓取速度。
* **自动去重**：内置 URL 去重机制，避免重复下载同一张图片。



## 🛠️ 安装与使用

### 1. 环境准备

确保您的电脑上已安装 Python 3.8 或更高版本。

```Bash
# 克隆项目到本地
git clone https://github.com/xuexiren/Crawl-the-image-library.git

# 进入项目目录
cd Crawl-the-image-library
```

### 2. 安装依赖

使用 pip 安装所需的第三方库：

```Bash
pip install -r requirements.txt
```

### 3. 运行爬虫

直接运行主程序：

```Bash
python main.py
```

### 4. 操作指南

程序启动后，请按照命令行提示输入：

1. **请输入关键词**：例如 `风景`、`二次元`、`猫咪`
2. **请输入数量**：希望从每个搜索引擎爬取的图片数量（例如 `100`）

程序将自动开始抓取，图片会保存在当前目录下的 `imgs/` 文件夹中。

## ⚠️ 免责声明

1. 本项目仅供**学习和技术研究**使用。
2. 请勿使用本工具爬取受版权保护的图片用于商业用途。
3. 请合理设置爬取频率和数量，避免对目标网站服务器造成不必要的压力。
4. 使用本工具产生的一切法律后果由使用者自行承担。
